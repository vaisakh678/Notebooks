{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6Q3iJ2WJ-Jcq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "T3XMkgmk_qZc",
        "outputId": "2c584db0-a984-4fa2-f114-523e7f07160b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>User_id,Product_id,Rating,Date,Review,Label</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>923,0,3,12/8/2014,The food at snack is a selec...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>924,0,3,5/16/2013,\"This little place in Soho i...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>925,0,4,7/1/2013,\"ordered lunch for 15 from Sn...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>926,0,4,7/28/2011,\"This is a beautiful quaint ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359048</th>\n",
              "      <td>161146,349,5,2/6/2014,\"I'm very spoiled with P...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359049</th>\n",
              "      <td>116424,349,5,1/31/2014,\"Can't say enough good ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359050</th>\n",
              "      <td>161147,349,5,1/30/2014,\"Had a great dinner her...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359051</th>\n",
              "      <td>97930,349,5,1/25/2014,\"Great foods and great d...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359052</th>\n",
              "      <td>5260,349,5,1/25/2014,\"Pizza Loves Emily and I ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>359053 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Review  label\n",
              "0             User_id,Product_id,Rating,Date,Review,Label    NaN\n",
              "1       923,0,3,12/8/2014,The food at snack is a selec...    NaN\n",
              "2       924,0,3,5/16/2013,\"This little place in Soho i...    NaN\n",
              "3       925,0,4,7/1/2013,\"ordered lunch for 15 from Sn...    NaN\n",
              "4       926,0,4,7/28/2011,\"This is a beautiful quaint ...    NaN\n",
              "...                                                   ...    ...\n",
              "359048  161146,349,5,2/6/2014,\"I'm very spoiled with P...    NaN\n",
              "359049  116424,349,5,1/31/2014,\"Can't say enough good ...    NaN\n",
              "359050  161147,349,5,1/30/2014,\"Had a great dinner her...    NaN\n",
              "359051  97930,349,5,1/25/2014,\"Great foods and great d...    NaN\n",
              "359052  5260,349,5,1/25/2014,\"Pizza Loves Emily and I ...    NaN\n",
              "\n",
              "[359053 rows x 2 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filepath = \"/Users/vaisakh/programs/Notebooks/dataset/Labelled Yelp Dataset.csv\"\n",
        "df = pd.read_csv(filepath, names=['Review', 'label'], sep='\\t')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZF_yBAxvAc78"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "review = df['Review'].values\n",
        "y=df['label'].values\n",
        "review_train, review_test, y_train, y_test  = train_test_split(review, y, test_size= 0.25, random_state=1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Urx-yjMqCo07",
        "outputId": "dfb067ac-bd3f-48ab-fd1d-2db3c4eb5360"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<269289x244408 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 21270800 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(review_train)\n",
        "\n",
        "X_train = vectorizer.transform(review_train)\n",
        "X_test = vectorizer.transform(review_test)\n",
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 58137)\t1\n",
            "  (0, 108684)\t1\n",
            "  (0, 113842)\t1\n",
            "  (0, 135307)\t1\n",
            "  (0, 137656)\t1\n",
            "  (0, 137917)\t1\n",
            "  (0, 138366)\t4\n",
            "  (0, 140126)\t1\n",
            "  (0, 143241)\t1\n",
            "  (0, 143414)\t1\n",
            "  (0, 144193)\t1\n",
            "  (0, 144518)\t1\n",
            "  (0, 147659)\t1\n",
            "  (0, 148808)\t1\n",
            "  (0, 148816)\t2\n",
            "  (0, 149827)\t1\n",
            "  (0, 151624)\t1\n",
            "  (0, 153908)\t1\n",
            "  (0, 154461)\t1\n",
            "  (0, 155332)\t1\n",
            "  (0, 157711)\t1\n",
            "  (0, 161758)\t1\n",
            "  (0, 162746)\t1\n",
            "  (0, 162992)\t1\n",
            "  (0, 165348)\t1\n",
            "  :\t:\n",
            "  (269288, 183873)\t1\n",
            "  (269288, 184287)\t1\n",
            "  (269288, 198478)\t1\n",
            "  (269288, 200341)\t1\n",
            "  (269288, 200352)\t1\n",
            "  (269288, 200961)\t1\n",
            "  (269288, 201506)\t1\n",
            "  (269288, 205069)\t1\n",
            "  (269288, 215637)\t1\n",
            "  (269288, 218440)\t1\n",
            "  (269288, 223538)\t1\n",
            "  (269288, 223979)\t2\n",
            "  (269288, 224668)\t1\n",
            "  (269288, 224778)\t1\n",
            "  (269288, 231469)\t2\n",
            "  (269288, 232716)\t2\n",
            "  (269288, 234893)\t1\n",
            "  (269288, 237398)\t1\n",
            "  (269288, 239980)\t1\n",
            "  (269288, 240084)\t1\n",
            "  (269288, 240705)\t1\n",
            "  (269288, 241212)\t1\n",
            "  (269288, 243297)\t2\n",
            "  (269288, 243325)\t1\n",
            "  (269288, 243892)\t1\n"
          ]
        }
      ],
      "source": [
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhXCMoczDM-R",
        "outputId": "6f256891-0036-45fe-9068-008eea996069"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(269289, 244408)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "a5bnv4LGD48h"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metal device set to: Apple M1\n",
            "\n",
            "systemMemory: 8.00 GB\n",
            "maxCacheSize: 2.67 GB\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-13 11:58:08.790425: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2022-12-13 11:58:08.791753: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        }
      ],
      "source": [
        "#Model1\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(layers.Dense(10, input_dim = input_dim, activation='relu'))\n",
        "model1.add(layers.Dense(1, activation='sigmoid'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsNdOVV5FD11",
        "outputId": "6206ed3f-57fa-4d32-810f-c3b45791283e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                2444090   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,444,101\n",
            "Trainable params: 2,444,101\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model1.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqmOIPwkFYaY",
        "outputId": "5a9e7235-8dcc-4e37-aa75-3eb8561c316e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            " 2544/26929 [=>............................] - ETA: 32:24 - loss: nan - accuracy: 0.0000e+00"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model1\u001b[39m.\u001b[39;49mfit(X_train, y_train, \n\u001b[1;32m      2\u001b[0m                      epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, \n\u001b[1;32m      3\u001b[0m                      \n\u001b[1;32m      4\u001b[0m                      validation_data\u001b[39m=\u001b[39;49m(X_test, y_test),\n\u001b[1;32m      5\u001b[0m                      batch_size\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
            "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
            "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history = model1.fit(X_train, y_train, \n",
        "                     epochs=2, \n",
        "                     \n",
        "                     validation_data=(X_test, y_test),\n",
        "                     batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqNSqJr8GH4B",
        "outputId": "f3282215-3ee6-44c1-ad45-507efb9eeab9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1268 - accuracy: 0.9933\n",
            "Training Accuracy :  0.9933333396911621\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7760\n",
            "Test Accuracy :  0.7760000228881836\n"
          ]
        }
      ],
      "source": [
        "from keras.metrics import accuracy\n",
        "loss, accuracy = model1.evaluate(X_train, y_train )\n",
        "print(\"Training Accuracy : \", format(accuracy))\n",
        "\n",
        "loss, accuracy = model1.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy : \", format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsyT95F-Ikce",
        "outputId": "87b83dff-81c5-440a-94a0-b1c5bbc2571c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4826,39,4,12/26/2008,\"I love this small cosy, romantic set-up. It's fun to sit by the chef's bar but I this place is tiny... I remember having to squeeze 6 peeps around a center table one time but on other occasions I have enjoyed dinner for 2 in a romantic spot by the window, dim lightings and all. Haven't been here of late but I used to love this small cosy neighborhood chill out spot by Batali. Fav dishes include - Croquette - Razor clams (didn't they used to have cockles?) - many other inventive dishes from various animal parts (heh) Go figure! Love the portion sizes. Could be a tad expensive at times but what the heck. Plus point is that they are open late. I recall one time heading here after a ballet as it was one of the few places that still served after 10pm. I think we were here till 1am or so ... sweet.\",1\n",
            "[2825, 30, 127, 472, 543, 4, 101, 16, 128, 4646, 945, 773, 66, 48, 432, 5, 381, 81, 1, 2214, 125, 14, 4, 16, 28, 9, 479, 4, 592, 405, 5, 2503, 111, 173, 3, 1943, 109, 46, 60, 14, 20, 105, 2189, 4, 31, 318, 124, 10, 52, 11, 3, 945, 209, 81, 1, 1206, 1701, 2, 39, 799, 96, 38, 7, 457, 14, 4, 492, 5, 101, 16, 128, 4646, 363, 1386, 45, 209, 81, 3883, 2371, 186, 1986, 4116, 4556, 1168, 129, 29, 492, 5, 31, 229, 105, 2761, 186, 61, 1607, 4351, 2145, 54, 1933, 101, 1, 446, 1870, 142, 35, 3, 1535, 606, 33, 234, 14, 80, 1, 3256, 623, 447, 9, 15, 29, 32, 385, 457, 4, 2455, 46, 60, 2619, 38, 110, 3, 34, 8, 6, 46, 7, 1, 189, 269, 15, 172, 268, 110, 2691, 4, 144, 18, 25, 38, 2170, 56, 26, 207, 12]\n",
            "265004\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(num_words = 5000)\n",
        "tokenizer.fit_on_texts(review_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(review_train)\n",
        "X_test = tokenizer.texts_to_sequences(review_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(review_train[500])\n",
        "print(X_train[500])\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "evAswLhCKJiZ"
      },
      "outputs": [],
      "source": [
        "from keras_preprocessing.sequence import pad_sequences\n",
        "maxlen = 100\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edJmoFqlLIEB",
        "outputId": "a9c5a9d1-b807-4495-dd83-64b9fe7f1626"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 50)           13250200  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                50010     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,300,221\n",
            "Trainable params: 13,300,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Model 2\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "\n",
        "embedding_dem = 50\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(layers.Embedding( input_dim = vocab_size,\n",
        "                            output_dim=embedding_dem,\n",
        "                            input_length=maxlen))\n",
        "model2.add(layers.Flatten())\n",
        "model2.add(layers.Dense(10,  activation='relu'))\n",
        "model2.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model2.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Otd1jmvXJkCe",
        "outputId": "e701580c-872c-4824-a86e-70cf50f0f17a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-13 12:04:14.787779: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   33/26929 [..............................] - ETA: 1:21:46 - loss: nan - accuracy: 0.0000e+00"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model2\u001b[39m.\u001b[39;49mfit(X_train, y_train, \n\u001b[1;32m      2\u001b[0m                      epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, \n\u001b[1;32m      3\u001b[0m                      validation_data\u001b[39m=\u001b[39;49m(X_test, y_test),\n\u001b[1;32m      4\u001b[0m                      batch_size\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
            "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
            "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history = model2.fit(X_train, y_train, \n",
        "                     epochs=2, \n",
        "                     validation_data=(X_test, y_test),\n",
        "                     batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCD9baL1N5Cd",
        "outputId": "d3488f23-4702-4435-8649-64bf7418c49a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5067\n",
            "Training Accuracy :  0.5066666603088379\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.4800\n",
            "Test Accuracy :  0.47999998927116394\n"
          ]
        }
      ],
      "source": [
        "from keras.metrics import accuracy\n",
        "loss, accuracy = model2.evaluate(X_train, y_train )\n",
        "print(\"Training Accuracy : \", format(accuracy))\n",
        "\n",
        "loss, accuracy = model2.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy : \", format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doiLwXW4TwCm"
      },
      "outputs": [],
      "source": [
        "# Model 3\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "\n",
        "embedding_dem = 100\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(layers.Embedding( vocab_size, embedding_dem, input_length=maxlen))\n",
        "model3.add(layers.Conv1D(32, 3, activation='relu'))\n",
        "model3.add(layers.GlobalMaxPooling1D())\n",
        "model3.add(layers.Dense(10,  activation='relu'))\n",
        "model3.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4F-lKX0-U0gw"
      },
      "outputs": [],
      "source": [
        "history = model3.fit(X_train, y_train, \n",
        "                     epochs=50, \n",
        "                     verbose=False,\n",
        "                     validation_data=(X_test, y_test),\n",
        "                     batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5X2KtzLU3VO",
        "outputId": "f8146bb2-40bf-4916-a191-f0a562af0e58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy :  1.0\n",
            "Test Accuracy :  0.8080000281333923\n"
          ]
        }
      ],
      "source": [
        "from keras.metrics import accuracy\n",
        "loss, accuracy = model3.evaluate(X_train, y_train , verbose=False,)\n",
        "print(\"Training Accuracy : \", format(accuracy))\n",
        "\n",
        "loss, accuracy = model3.evaluate(X_test, y_test, verbose=False,)\n",
        "print(\"Test Accuracy : \", format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4gZ-LRbWqqG"
      },
      "outputs": [],
      "source": [
        "#32, 3 = 81.59\n",
        "#32, 5 = 80\n",
        "#32, 7 = 80.40\n",
        "#64, 3 = 80.80\n",
        "#64, 5 = 80\n",
        "#64, 7 = 79.19\n",
        "#128, 3 = 79.60\n",
        "#128, 5 = 78.39\n",
        "#128, 7 = 80.80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXiDUKTAX7Kt"
      },
      "outputs": [],
      "source": [
        "#Model 4\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "\n",
        "embedding_dem = 100\n",
        "\n",
        "model4 = Sequential()\n",
        "model4.add(layers.Embedding( vocab_size, embedding_dem, input_length=maxlen))\n",
        "model4.add(layers.SimpleRNN(128,return_sequences=True))\n",
        "\n",
        "model4.add(layers.SimpleRNN(128))\n",
        "\n",
        "model4.add(layers.Dense(10,activation='relu'))\n",
        "\n",
        "model4.add(layers.Dense(1,activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "model4.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOmpLhafZX8c"
      },
      "outputs": [],
      "source": [
        "history = model4.fit(X_train, y_train, \n",
        "                     epochs=10, \n",
        "                     verbose=False,\n",
        "                     validation_data=(X_test, y_test),\n",
        "                     batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QfWc6MCZaPE",
        "outputId": "08dab22f-fe9f-438f-f1cb-2d8acf79413a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy :  0.4933333396911621\n",
            "Test Accuracy :  0.5199999809265137\n"
          ]
        }
      ],
      "source": [
        "from keras.metrics import accuracy\n",
        "loss, accuracy = model4.evaluate(X_train, y_train , verbose=False,)\n",
        "print(\"Training Accuracy : \", format(accuracy))\n",
        "\n",
        "loss, accuracy = model4.evaluate(X_test, y_test, verbose=False,)\n",
        "print(\"Test Accuracy : \", format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH-6LKtnAFTg",
        "outputId": "cf57a331-340b-4eae-b4da-745876d1257f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 100, 100)          174700    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100, 128)          117248    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100, 128)          0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 424,833\n",
            "Trainable params: 424,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#model5 LSTM\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "\n",
        "embedding_dem = 100\n",
        "\n",
        "model5 = Sequential()\n",
        "model5.add(layers.Embedding( vocab_size, embedding_dem, input_length=maxlen))\n",
        "model5.add(layers.LSTM(128,return_sequences=True))\n",
        "model5.add(layers.Dropout(0.2))\n",
        "model5.add(layers.LSTM(128))\n",
        "\n",
        "model5.add(layers.Dense(10,activation='relu'))\n",
        "\n",
        "model5.add(layers.Dense(1,activation='softmax'))\n",
        "\n",
        "model5.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model5.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6stYKsPAuIR",
        "outputId": "5afdb82b-a3a3-428b-b578-d7c529a97fff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "75/75 [==============================] - 20s 221ms/step - loss: 0.6943 - accuracy: 0.4933 - val_loss: 0.6932 - val_accuracy: 0.5200\n",
            "Epoch 2/10\n",
            "75/75 [==============================] - 14s 193ms/step - loss: 0.6932 - accuracy: 0.4933 - val_loss: 0.6933 - val_accuracy: 0.5200\n",
            "Epoch 3/10\n",
            "75/75 [==============================] - 15s 194ms/step - loss: 0.6931 - accuracy: 0.4933 - val_loss: 0.6934 - val_accuracy: 0.5200\n",
            "Epoch 4/10\n",
            "75/75 [==============================] - 14s 193ms/step - loss: 0.6932 - accuracy: 0.4933 - val_loss: 0.6934 - val_accuracy: 0.5200\n",
            "Epoch 5/10\n",
            "75/75 [==============================] - 15s 195ms/step - loss: 0.6931 - accuracy: 0.4933 - val_loss: 0.6934 - val_accuracy: 0.5200\n",
            "Epoch 6/10\n",
            "75/75 [==============================] - 15s 197ms/step - loss: 0.6931 - accuracy: 0.4933 - val_loss: 0.6934 - val_accuracy: 0.5200\n",
            "Epoch 7/10\n",
            "75/75 [==============================] - 15s 196ms/step - loss: 0.6931 - accuracy: 0.4933 - val_loss: 0.6936 - val_accuracy: 0.5200\n",
            "Epoch 8/10\n",
            "75/75 [==============================] - 15s 195ms/step - loss: 0.6931 - accuracy: 0.4933 - val_loss: 0.6935 - val_accuracy: 0.5200\n",
            "Epoch 9/10\n",
            "75/75 [==============================] - 15s 197ms/step - loss: 0.6931 - accuracy: 0.4933 - val_loss: 0.6935 - val_accuracy: 0.5200\n",
            "Epoch 10/10\n",
            "75/75 [==============================] - 15s 197ms/step - loss: 0.6931 - accuracy: 0.4933 - val_loss: 0.6936 - val_accuracy: 0.5200\n"
          ]
        }
      ],
      "source": [
        "history = model5.fit(X_train, y_train, \n",
        "                     epochs=10, \n",
        "                     \n",
        "                     validation_data=(X_test, y_test),\n",
        "                     batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grEJUycVAxRE",
        "outputId": "f4037436-82ba-41bc-fcbd-6691bd668911"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy :  0.4933333396911621\n",
            "Test Accuracy :  0.5199999809265137\n"
          ]
        }
      ],
      "source": [
        "from keras.metrics import accuracy\n",
        "loss, accuracy = model5.evaluate(X_train, y_train , verbose=False,)\n",
        "print(\"Training Accuracy : \", format(accuracy))\n",
        "\n",
        "loss, accuracy = model5.evaluate(X_test, y_test, verbose=False,)\n",
        "print(\"Test Accuracy : \", format(accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAEVFlfKA2Uc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "e54217f9e10c9c2ab2c5acb791143dc555f80e81eec2f2e8946a5b329595e68c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
